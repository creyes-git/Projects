from langchain_groq import ChatGroq
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_community.chat_message_histories import StreamlitChatMessageHistory
from langchain_core.messages import AIMessage, HumanMessage, SystemMessage
from dotenv import load_dotenv


load_dotenv() # Load the .env file


# Initializing the LLM
llm = ChatGroq(model = "llama-3.3-70b-versatile",
               temperature = 1.5,
               max_tokens = 20000,
               timeout = None,
               max_retries = 2,
               stop_sequences = None)
    

# This library stores the conversation history in streamlit memory, allowing the agent to mantain context during the conversation
system_message = ("You are a professional screenwriter with expertise in crafting engaging scripts for YouTube videos."
                  "Your role is to assist the user in creating compelling narratives and answering questions regarding their script."
                  "Please use the provided context and topic to inform your responses about the script's history."
                  "If a question falls outside the realm of scriptwriting for YouTube videos, respond with 'I am not an expert' and then answer."
                  "\n\n"
                  "{input}")


qa_prompt = ChatPromptTemplate.from_messages([MessagesPlaceholder(variable_name = "chat_history"),
                                                                 ("human", "{input}"),
                                                                 ("system", system_message)])


# Create the CHAIN with the prompt and LLM
chain = qa_prompt | llm


memory = StreamlitChatMessageHistory()
memory.add_message(SystemMessage(content = system_message)) # Start the conversation with the system message


def talk_with_screenwriter(user_input : str):
    """
    Process the user's input by adding it to the conversation history, 
    invoking the agent executor to generate a response, and updating the 
    conversation history with the AI's response.
    
    Args:
        user_input (str): The input message from the user.

    Returns:
       str: The response generated by the agent based on the user's input.
    """
    
    memory.add_message(HumanMessage(content = user_input))
    
    response = chain.invoke({"input": user_input, "chat_history": memory.messages})
    
    memory.add_message(AIMessage(content = response.content))
    
    
    return response.content
    

def clear_memory():
    "Clear the conversation history and reset the agent to the initial state by adding the system message again to the memory."
    memory.clear()
    memory.add_message(SystemMessage(content = system_message))